{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM from scratch \n",
    "\n",
    "We follow this [tutorial](https://medium.com/@msouza.os/llm-from-scratch-with-pytorch-9f21808c6319)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Idea**: need to make the machine able to read text. Since it can only understand numbers, need to _encode text into numbers_. Since humans can only understand text, we need to be able to _decode numbers into text_\n",
    "\n",
    "=> need numeric representation of text \n",
    "\n",
    "1. split text into sequence of words (_tokens_)\n",
    "2. for each word (_token_) in model vocabulrary, assign integer\n",
    "\n",
    "There are several different models for tokenizers. Note that model performance during training will be affected by chosen tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "\n",
    "    @staticmethod\n",
    "    def create_vocab(dataset:str,mode='char',ukn=True)->dict[str:str]:\n",
    "        \"\"\"\n",
    "        Create vocabulary\n",
    "\n",
    "        :param dataset: Text data to be used to define vocabulary\n",
    "        :type dataset: str\n",
    "\n",
    "        :returns: (word) vocabulary  \n",
    "        :rtype: dict[str:int]\n",
    "        \"\"\"\n",
    "\n",
    "        # CREATE VOCABULRARY\n",
    "        if mode == 'char':\n",
    "            vocab = {tkn:idx for idx,tkn in enumerate(sorted(set(dataset)))}\n",
    "        elif mode == 'word':\n",
    "            pattern_ = re.compile(r'(?<=\\w)(?=[^\\w])|(?<=[^\\w])(?=\\w)|(?<=[^\\w])(?=\\s)|(?<=[^\\w])(?=[^w])') # pattern splits string into words, spaces and special characters\n",
    "            words_in_data = pattern_.split(dataset)\n",
    "            vocab = {tkn:idx for idx,tkn in enumerate(sorted(set(words_in_data)))}\n",
    "\n",
    "        # ADD UNKNOWN TOKEN\n",
    "        if ukn:\n",
    "            vocab['<ukn>'] = len(vocab)\n",
    "\n",
    "        return vocab\n",
    "    \n",
    "\n",
    "    def __init__(self,vocab:dict[str,int],mode='char',ukn=True) -> None:\n",
    "        \"\"\"\n",
    "        Initialize tokenizer\n",
    "\n",
    "        :param vocab: vocabulary to intitalize\n",
    "        :type vocab: dict[str:int]\n",
    "        \"\"\"\n",
    "        self.mode = mode # mode: word or char\n",
    "        self.ukn = ukn # <ukn> token\n",
    "        self.vocab_encode = {str(k): int(v) for k, v in vocab.items()} # encode vocab: key:value = char:int\n",
    "        self.vocab_decode = {v: k for k, v in self.vocab_encode.items()} # decode vocab key:value = int:char\n",
    "        if self.mode == 'word':\n",
    "            self.pattern = re.compile(r'(?<=\\w)(?=[^\\w])|(?<=[^\\w])(?=\\w)|(?<=[^\\w])(?=\\s)|(?<=[^\\w])(?=[^w])')\n",
    "\n",
    "    def encode(self,text:str):\n",
    "        \"\"\"\n",
    "        Encode text in (lvl: character)\n",
    "\n",
    "        :param text: Input text to encode\n",
    "        :type text: str\n",
    "\n",
    "        :returns: encoded text (list with token indices)\n",
    "        :rtype: list[int]\n",
    "        \"\"\"\n",
    "\n",
    "        if self.mode == 'word':\n",
    "            text_ = self.pattern.split(text)\n",
    "        else:\n",
    "            text_ = text\n",
    "        \n",
    "        if self.ukn:\n",
    "            encoded_txt = [self.vocab_encode.get(word,self.vocab_encode['<ukn>']) for word in text_]\n",
    "        else:\n",
    "            encoded_txt = [self.vocab_encode.get(word) for word in text_]\n",
    "\n",
    "        return encoded_txt\n",
    "    \n",
    "    def decode(self,idxs:list[int]):\n",
    "        \"\"\"\n",
    "        Decode a list of token indices\n",
    "\n",
    "        :param idxs: List of token indices\n",
    "        :type idxs: list[int]\n",
    "\n",
    "        :returns: Decoded text\n",
    "        :rtype: str\n",
    "        \"\"\"\n",
    "\n",
    "        if self.ukn:\n",
    "            decoded_txt = [self.vocab_decode.get(idx,'<ukn>') for idx in idxs]\n",
    "        else:\n",
    "            decoded_txt = [self.vocab_decode.get(idx) for idx in idxs]\n",
    "\n",
    "        return ''.join(decoded_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc = [4, 6, 11, 11, 12, 0, 5, 7, 11, 15, 0, 16, 16]\n",
      "\n",
      "dec = 'Hallo Welt <ukn><ukn>'\n"
     ]
    }
   ],
   "source": [
    "dataset = 'Hallo Welt! Wie geht es Dir?'\n",
    "mode = 'char'\n",
    "\n",
    "vocab = Tokenizer.create_vocab(dataset,mode=mode)\n",
    "\n",
    "tokenize = Tokenizer(vocab,mode=mode)\n",
    "\n",
    "test = 'Hallo Welt :)'\n",
    "\n",
    "enc = tokenize.encode(test)\n",
    "dec = tokenize.decode(enc)\n",
    "\n",
    "print(f'{enc = }\\n')\n",
    "print(f'{dec = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov Chain LLM\n",
    "\n",
    "An easy implementation of a next-token-predictor using only the context of the previous token (like a Markov Chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1089k  100 1089k    0     0  3225k      0 --:--:-- --:--:-- --:--:-- 3222k\n"
     ]
    }
   ],
   "source": [
    "!curl https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt -o TinyShakespeare.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"TinyShakespeare.txt\",\"r\") as file:\n",
    "    text = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chars in vocab:\n",
      " \n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "\n",
      "vocab_size = 65\n"
     ]
    }
   ],
   "source": [
    "mode = 'char' # char vocabulary\n",
    "ukn = False # omit <ukn> token\n",
    "\n",
    "vocab = Tokenizer.create_vocab(text,mode,ukn)\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(f\"chars in vocab:\\n {r''.join(list(vocab.keys()))}\\n\")\n",
    "\n",
    "print(f'{vocab_size = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_ = F               next_token = 'i'\n",
      "context_ = Fi              next_token = 'r'\n",
      "context_ = Fir             next_token = 's'\n",
      "context_ = Firs            next_token = 't'\n",
      "context_ = First           next_token = ' '\n",
      "context_ = First           next_token = 'C'\n",
      "context_ = First C         next_token = 'i'\n",
      "context_ = First Ci        next_token = 't'\n"
     ]
    }
   ],
   "source": [
    "# PREPARING DATA\n",
    "tokenize = Tokenizer(vocab,ukn=ukn)\n",
    "\n",
    "encode = tokenize.encode\n",
    "decode = lambda s: tokenize.decode(s.tolist()) # s tensor\n",
    "\n",
    "data = torch.tensor(encode(text),dtype=int) # encoded text\n",
    "\n",
    "\n",
    "# SPLIT TRAIN - VALDIATION\n",
    "split = int(0.9*len(data))\n",
    "\n",
    "data_train = data[:split]\n",
    "data_val = data[split:]\n",
    "\n",
    "context_size = 8\n",
    "batch_size = 4 \n",
    "\n",
    "context = data[:context_size]\n",
    "target = data[1:context_size+1]\n",
    "\n",
    "# DISPLAY CONTEXT AND TARGET (NEXT TOKEN IN SEQUENCE)\n",
    "for t in range(context_size):\n",
    "    context_ = decode(context)[:t+1]\n",
    "    next_token = decode(target)[t]\n",
    "    \n",
    "    print(f'{context_ = :<15} {next_token = }')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split:str):\n",
    "    \"\"\"\n",
    "    Grabs batch of context-chuncks from training / validation data\n",
    "\n",
    "    :params split: which \"split\" (train / validation) of data to grab from\n",
    "    :type split: str\n",
    "\n",
    "    :returns: context and corresponding target predictions\n",
    "    :rtype: tuple(torch.tensor,torch.tensor)\n",
    "    \"\"\"\n",
    "    data = data_train if split == 'train' else data_val\n",
    "\n",
    "    start = torch.randint(low=0,high=len(data) - context_size,size=(batch_size,)) # grab random starting points in data ( = rnd indices)\n",
    "\n",
    "    context = torch.stack( [data[t:t+context_size] for t in start] ) \n",
    "    target = torch.stack( [data[t+1:t+1+context_size] for t in start] )\n",
    "\n",
    "    return context, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test get_batch():\n",
      "\n",
      "contexts.shape = torch.Size([4, 8])\n",
      "targets.shape = torch.Size([4, 8])\n"
     ]
    }
   ],
   "source": [
    "# TEST get_batch()\n",
    "torch.manual_seed(57)\n",
    "contexts, targets = get_batch('train')\n",
    "\n",
    "print('Test get_batch():\\n')\n",
    "print(f'{contexts.shape = }')\n",
    "print(f'{targets.shape = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE MODEL\n",
    "class MarkovChainLLM(nn.Module):\n",
    "\n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding_table = nn.Embedding(num_embeddings=vocab_size, embedding_dim=vocab_size)  # embedding table \n",
    "\n",
    "    def forward(self,contexts,targets=None):\n",
    "        # PREDICTIONS / LOGITS\n",
    "        logits = self.embedding_table(contexts) # context = encoded characters = sequence of integers: dim (b,t,c) = (batch, time, channel)\n",
    "\n",
    "\n",
    "        if targets == None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # RESHUFFLE TO HAND TO ENTROPY\n",
    "            b,t,c = logits.shape\n",
    "        \n",
    "            logits = logits.view(b*t,c)\n",
    "            y = targets.view(b*t)\n",
    "\n",
    "            loss = F.cross_entropy(logits,y)\n",
    "            \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self,idx,max_new_tokens):\n",
    "        \"\"\"\n",
    "        Genereate new tokens.\n",
    "\n",
    "        Idea:\n",
    "        -----\n",
    "        Perform a random (Markov Chain) walk in the vocabulrary based on transition probabilities stored in the embedding table.\n",
    "        This means, one starts with a token and grabs the associated probabilities for the next token from the embedding table. \n",
    "        Then, sample and jump (predict) to the the next token according to those probabilities (i.e. via a 1-step multinomial distribution) and repeat.\n",
    "        The Markov Property enters in the assumption that the context used to predict the next token is given **only** by the current token.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        idx: torch.tensor\n",
    "            encoded starting context \n",
    "\n",
    "        max_new_tokens: int\n",
    "            number of tokens to predict\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        idx: list[int]\n",
    "            list of new tokens (encoded predicted characters)\n",
    "        \"\"\"\n",
    "\n",
    "        # idx.shape = (b,t) in current context\n",
    "        # notation: b = batch dim, t = time dim (len context), c = channels (len vocab)\n",
    "\n",
    "        for _ in range(max_new_tokens):\n",
    "\n",
    "            # PREDICT\n",
    "            logits, _ = self(idx) # if no target are specified, the forward method extract row `idx` from embedding table => (b,t,c)\n",
    "\n",
    "            # MARKOV PROPERTY\n",
    "            logits = logits[:,-1,:] # => (b,c)\n",
    "\n",
    "            # TAKE RANDOM SAMPLE\n",
    "            probas = F.softmax(logits,dim=-1) # softmax over channels dimension => shape (b,)\n",
    "            \n",
    "\n",
    "            next_idx = torch.multinomial(probas,num_samples=1) # pick token from vocab => (1,)\n",
    "\n",
    "            idx = torch.cat((idx,next_idx),dim=1) # (b,t+1)\n",
    "\n",
    "        return idx\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST MODEL\n",
    "contexts, targets = get_batch('train')\n",
    "\n",
    "model = MarkovChainLLM(vocab_size)\n",
    "\n",
    "logits, loss = model(contexts,targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test token generation before training:\n",
      "\n",
      "NwFLgccgcTEZ-EcVTIak?qM'';o\n",
      "P$O;aGQH-E3Y$cn;EHz,iwhtsBubkZKMKIIDnvgbxId -InrUCgcTgzXIn;Uv\n",
      "YgzwZVkZ-k\n"
     ]
    }
   ],
   "source": [
    "# TEST MarkovChainLLM.generate() BEFORE TRAINING\n",
    "start = torch.zeros(1,1,dtype=torch.long)\n",
    "max_new_tokens = 100\n",
    "\n",
    "print('Test token generation before training:')\n",
    "print(decode(model.generate(idx = start,max_new_tokens = max_new_tokens)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab(x):\n",
    "    \"\"\"\n",
    "    Grabs and detaches given torch.tensor\n",
    "    \"\"\"\n",
    "    return x.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:08<00:00, 1218.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16a15a350>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TRAINING\n",
    "alpha = 1e-3 # learning rate\n",
    "optimizer = optim.AdamW(model.parameters(),lr = alpha) # optimizer\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "epochs = 10_000\n",
    "\n",
    "losses_train = []\n",
    "losses_val = []\n",
    "\n",
    "for epoch in tqdm.tqdm(range(epochs)):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    contexts_train, targets_train = get_batch('train')\n",
    "    contexts_val, targets_val = get_batch('val')\n",
    "\n",
    "    # FORWARD\n",
    "    logits_train, loss_train = model(contexts_train,targets_train)\n",
    "\n",
    "    # BACKPROPAGATION\n",
    "    loss_train.backward()\n",
    "\n",
    "    # UPDATE PARAMETERS\n",
    "    optimizer.step()\n",
    "\n",
    "    # VALIDATION\n",
    "    with torch.no_grad():\n",
    "        logits_val, loss_val = model(contexts_val,targets_val)\n",
    "\n",
    "\n",
    "    losses_train.append(grab(loss_train))\n",
    "    losses_val.append(grab(loss_val))\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "ax.plot(losses_train,label = 'train')\n",
    "ax.plot(losses_val,label = 'val')\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test token generation after training:\n",
      "\n",
      "bl asherir s cthaCLLisw an-lo fotoo BOfou man:\n",
      "CRDUEELLKI:\n",
      "\n",
      "Thir lllofall den!'lyinfrtorshat oWilice\n"
     ]
    }
   ],
   "source": [
    "# TEST MarkovChainLLM.generate() AFTER TRAINING\n",
    "start = torch.zeros(1,1,dtype=torch.long)\n",
    "max_new_tokens = 100\n",
    "print('Test token generation after training:')\n",
    "print(decode(model.generate(idx = start, max_new_tokens = max_new_tokens)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The *Attention is all you need* Architecthure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Idea:** We want the computer to understand the symmantics (not only syntax). Thus we need to teach it what words (characters) are _similar_. To do so, we use vector represetnations (**embeddings**) of the tokens. These embeddings come with learnable parameters that can be adjusted during training to imporve the representation. The embedding is thus a map from the vocabulary $V$ to some vector space $X$: $E \\colon V \\to X$. If $\\dim(V) = N$ (length of vodabulary) and $\\dim(X) = d$, then the embedding is a _linear_ map $E \\colon \\mathbb{R}^N \\to \\mathbb{R}^d$ so a $N \\times d$ matrix. \n",
    "\n",
    "Notice that the larger $d$, the more parameters can be learned and hence the more the model can learn more details about the dataset at the expense of computation time.\n",
    "\n",
    "\n",
    "**Implementation:** \n",
    "\n",
    "1. Assign to each token a random vector of parameters (which will be learned during training). Assume that the length of the vocabulary is $N$, and we embedd into a vector space of dimension $d$, the embedding space will be $\\mathbb{R}^N \\times \\mathbb{R}^d$ which can be represented as a matrix with $N$ rows and $d$ columns.\n",
    "\n",
    "2. To compute similarity, use _cosine_ distance: for $x,y \\in \\mathbb{R}^d$, define their cosine-distance by $d(x,y) = \\cos( \\sphericalangle (x,y) ) \\in [-1,1]$\n",
    "\n",
    "Note that \n",
    "\n",
    "$$ \\cos( \\sphericalangle (x,y) ) = \\frac{\\langle x, y \\rangle}{\\lVert x \\rVert \\lVert y \\rVert}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**!!** LLMs = Transformer based models\n",
    "\n",
    "**Transformer model architecture:** [Attention is all you need](https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)\n",
    "\n",
    "1. composed of 1 _encoder_ and 1 _decoder_ block (using attention mechanism called _Scaled Dot-Product Attention_)\n",
    "\n",
    "2. How they work\n",
    "    * Encoder block: tries to analyze each word considering the entire text context\n",
    "    * Decoder block: masks all future words at some specific position and uses only the _previous_ words available to analyze the current one\n",
    "    * Main block: _Multi-Head Attention_ (!! key component of LLMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Mechanism "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled Dot-Product Attention\n",
    "\n",
    "**Input:**\n",
    "* Q: query = information we're trying to find (relationship between tokens)\n",
    "* K: Key =  where you will find this information\n",
    "* V: Value\n",
    "\n",
    "\n",
    "\n",
    "**architecture:** \n",
    "\n",
    "```\n",
    "Q --> |\n",
    "      | MatMult --> Scale --> Mask(opt.) --> SoftMax --> |\n",
    "K --> |                                                  |   \n",
    "                                                         | -- MatMult -->\n",
    "                                                         |\n",
    "V ------------------------------------------------------>|\n",
    "```\n",
    "\n",
    "\n",
    "$Q,K,V$ are calculated by linear transformations (simple linear layers) from the embedded text. The workflow is roughly as follows: for $T \\in Mat(\\mathbb{R},N\\times N)$\n",
    "\n",
    "$\\text{text (str)} \\stackrel{E\\;(\\text{embedding})}{\\longrightarrow} Q,K \\in \\mathbb{R}^N \\times \\mathbb{R}^d \\stackrel{T}{\\longrightarrow} Q',K' \\in \\mathbb{R}^N \\times \\mathbb{R}^d  \\stackrel{Q K^t}{\\longrightarrow} R \\in \\mathbb{R}^N \\times \\mathbb{R}^N$ \n",
    "\n",
    "The output of this sequence is a $N\\times N$ matrix $R$ encoding the _relationship_ between our tokens. \n",
    "\n",
    "Next, we need to scale (to avoid 1-hot encoding) by $\\sqrt{N}$ ($N$ is called the _embedding dimension_) and then feed it into a SoftMax function to normalize each value to (0,1) such that each row sums up to 1. This defines the so-called _attention_\n",
    "\n",
    "$$A = \\frac{Q K^t}{\\sqrt{N}}$$\n",
    "\n",
    "Finally, we need to multiply it with the $V$ to obtain a \"vector representation\" if the information we were looking for:\n",
    "\n",
    "$$ \\text{out} = A V$$ \n",
    "\n",
    "_Remark_: It seems to be custom to scale A by the _embedding size_ $d$\n",
    "\n",
    "_NOTE_:  The attention mechanisim for transformers is trying to predict **every single token** in our sequence and not only the last one.\n",
    "However, during training we actually want to predict only the next token given a sequence of tokens as _context_. We could even look at a Markov Chain by considering only the previous token to predict the next one. The problem is that the output $out = A V$ considers _all_ possible tokens: the entire attention matrix $A$ is used.\n",
    "To overcome this problem, we mask $A$. We can multiply $A$ simply by a lower triangular matrix $M$ with all non-zero entries being 1. The mask then hides all consecutive tokens of all samples.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.size() = torch.Size([1, 9, 3])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# IMPLEMENTATION\n",
    "torch.random.manual_seed(seed=42)\n",
    "\n",
    "\n",
    "# DATA\n",
    "text = \"Hi! I am Donald.\"\n",
    "vocab = Tokenizer.create_vocab(text)\n",
    "tokenize = Tokenizer(vocab)\n",
    "\n",
    "tokens = tokenize.encode(text) # [4, 1, 0, 5, 0, 6, 0, 3, 2]\n",
    "tokens.reverse()\n",
    "\n",
    "# PARAMETERS\n",
    "# vocab_size = max(tokens) + 1 # numbers of tokens (classes) to predict \n",
    "vocab_size = max(vocab.values())  #N = numbers of tokens (classes) to predict (last class is <ukn> but 0 based)\n",
    "emb_dim = 3 # d = size of vecrep of each token\n",
    "context = len(tokens) # context size of model\n",
    "\n",
    "# LAYERS\n",
    "embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=emb_dim) # tokens = (N,) -> (N,3)\n",
    "query = nn.Linear(in_features=emb_dim, out_features=emb_dim, bias=False) # linear transformation on 2nd idx (N,3) -> (N,3) @ (3,3) = (N,3)\n",
    "key = nn.Linear(in_features=emb_dim, out_features=emb_dim, bias=False)\n",
    "value = nn.Linear(in_features=emb_dim, out_features=emb_dim, bias=False)\n",
    "\n",
    "# MASK\n",
    "ones = torch.ones(size=[context, context], dtype=torch.float)\n",
    "mask = torch.tril(input=ones) # lower triangular matrix \n",
    "\n",
    "# TOKEN IDXS FOR POS EMBEDDING\n",
    "tkn_idxs = torch.arange(context, dtype=torch.long)\n",
    "\n",
    "# FORWARD PASS\n",
    "t_tokens = torch.tensor(tokens).unsqueeze(dim=0) # (N,) -> (1,N)\n",
    "\n",
    "x = embedding(t_tokens) # (1,N) -> (1,N,d) embedded vectors\n",
    "\n",
    "B, T, C = x.size()\n",
    "\n",
    "# apply linear transformation T\n",
    "Q = query(x) # (1,N,d) -> (1,N,d) @ (1,d,d) = (1,N,d)\n",
    "K = key(x) \n",
    "V = value(x) \n",
    "\n",
    "# matmul\n",
    "QK = Q @ K.transpose(-2, -1) # (1,N,d) @ (1,d,N) -> (1,N,N)\n",
    "A = QK  * C**-0.5 # attention matrix \n",
    "A.masked_fill_(mask[:T,:T] == 0, float(\"-inf\")) # applying mask\n",
    "A = F.softmax(input=A, dim=-1) # apply SoftMax: (1,N,N) normalizing to 0 and 1 in embedding dimension\n",
    "\n",
    "out = A @ V # (1,N,N) @ (1,N,d) -> (1,N,d)\n",
    "\n",
    "# print(f'{out = }\\n') # new data representation\n",
    "print(f'{out.size() = }\\n') \n",
    "\n",
    "# x_before = x.detach().clone()\n",
    "x_after = x.detach().clone()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x before reversing the order of the token sequence\n",
      "tensor([[[-1.1109,  0.0418, -0.2516],\n",
      "         [-2.1055,  0.6784,  1.0783],\n",
      "         [ 1.9269,  1.4873,  0.9007],\n",
      "         [ 0.8599, -0.3097, -0.3957],\n",
      "         [ 1.9269,  1.4873,  0.9007],\n",
      "         [ 0.8034, -0.6216, -0.5920],\n",
      "         [ 1.9269,  1.4873,  0.9007],\n",
      "         [-0.6866, -0.4934,  0.2415],\n",
      "         [ 0.8008,  1.6806,  0.3559]]])\n"
     ]
    }
   ],
   "source": [
    "print('x before reversing the order of the token sequence')\n",
    "print(x_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x after reversing the order of the token sequence\n",
      "tensor([[[ 0.8008,  1.6806,  0.3559],\n",
      "         [-0.6866, -0.4934,  0.2415],\n",
      "         [ 1.9269,  1.4873,  0.9007],\n",
      "         [ 0.8034, -0.6216, -0.5920],\n",
      "         [ 1.9269,  1.4873,  0.9007],\n",
      "         [ 0.8599, -0.3097, -0.3957],\n",
      "         [ 1.9269,  1.4873,  0.9007],\n",
      "         [-2.1055,  0.6784,  1.0783],\n",
      "         [-1.1109,  0.0418, -0.2516]]])\n"
     ]
    }
   ],
   "source": [
    "print('x after reversing the order of the token sequence')\n",
    "print(x_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the entries in x _before_ and _after_ reversing the order of the input sequence of tokens are essentially the same up to orientation. \n",
    "The columns (same for rows) contain the same numbers but in reversed order, as seen below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:          after:          diff:\n",
      "-1.111          -1.111           0.000\n",
      "-2.106          -2.106           0.000\n",
      " 1.927           1.927           0.000\n",
      " 0.860           0.860           0.000\n",
      " 1.927           1.927           0.000\n",
      " 0.803           0.803           0.000\n",
      " 1.927           1.927           0.000\n",
      "-0.687          -0.687           0.000\n",
      " 0.801           0.801           0.000\n"
     ]
    }
   ],
   "source": [
    "x_before_col1 = [elem for elem in x_before[0][:,0]]\n",
    "x_after_col1 = [elem for elem in x_after[0][:,0]]\n",
    "x_after_col1.reverse()\n",
    "\n",
    "print(f'before: {\"after:\":>15} {\"diff:\":>14}')\n",
    "for i in range(len(x_before_col1)):\n",
    "    print(f'{x_before_col1[i]: .3f} {x_after_col1[i]: >15.3f} {x_before_col1[i] - x_after_col1[i]: >15.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Location of words in sentences matter.\n",
    "The vector representation should thereofre depend on the order of the token sequence.\n",
    "\n",
    "However, the attention mechanism above considers every token all at once in order to get a sense of _context_. Hence, we need to encode the positions by hand. This can be done by introducing another set of _positional_ parameters which can be learned. We simply define yet another embedding (of dimension context x emb_dim) and add it to our token embedding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out = tensor([[[-3.1104, -0.4777, -2.1211],\n",
      "         [-1.6634, -0.0585, -1.0139],\n",
      "         [-0.8581, -0.0070, -0.5185],\n",
      "         [ 0.0281,  0.2477,  0.1658],\n",
      "         [-0.4765,  0.1084, -0.1927],\n",
      "         [-0.0140,  0.1900,  0.1065],\n",
      "         [ 0.0133,  0.1353,  0.1065],\n",
      "         [ 0.1216,  0.0141,  0.0771],\n",
      "         [ 0.0057,  0.0227,  0.0102]]], grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "out.size() = torch.Size([1, 9, 3])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# IMPLEMENTATION\n",
    "torch.random.manual_seed(seed=42)\n",
    "\n",
    "\n",
    "# DATA\n",
    "text = \"Hi! I am Donald.\"\n",
    "vocab = Tokenizer.create_vocab(text)\n",
    "tokenize = Tokenizer(vocab)\n",
    "\n",
    "tokens = tokenize.encode(text) # [4, 1, 0, 5, 0, 6, 0, 3, 2]\n",
    "tokens.reverse()\n",
    "\n",
    "# PARAMETERS\n",
    "# vocab_size = max(tokens) + 1 # numbers of tokens (classes) to predict \n",
    "vocab_size = max(vocab.values())  #N = numbers of tokens (classes) to predict (last class is <ukn> but 0 based)\n",
    "emb_dim = 3 # d = size of vecrep of each token\n",
    "context = len(tokens) # context size of model\n",
    "\n",
    "# LAYERS\n",
    "pos_emb = nn.Embedding(num_embeddings=context, embedding_dim=emb_dim) # !! positional encoding \n",
    "embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=emb_dim) # tokens = (N,) -> (N,3)\n",
    "query = nn.Linear(in_features=emb_dim, out_features=emb_dim, bias=False) # linear transformation on 2nd idx (N,3) -> (N,3) @ (3,3) = (N,3)\n",
    "key = nn.Linear(in_features=emb_dim, out_features=emb_dim, bias=False)\n",
    "value = nn.Linear(in_features=emb_dim, out_features=emb_dim, bias=False)\n",
    "\n",
    "# MASK\n",
    "ones = torch.ones(size=[context, context], dtype=torch.float)\n",
    "mask = torch.tril(input=ones) # lower triangular matrix \n",
    "\n",
    "# TOKEN IDXS FOR POS EMBEDDING\n",
    "tkn_idxs = torch.arange(context, dtype=torch.long)\n",
    "\n",
    "# FORWARD PASS\n",
    "t_tokens = torch.tensor(tokens).unsqueeze(dim=0) # (N,) -> (1,N)\n",
    "\n",
    "x = embedding(t_tokens) # (1,N) -> (1,N,d) embedded vectors\n",
    "x += pos_emb(tkn_idxs) # !! add pos embeddings\n",
    "\n",
    "B, T, C = x.size()\n",
    "\n",
    "# apply linear transformation T\n",
    "Q = query(x) # (1,N,d) -> (1,N,d) @ (1,d,d) = (1,N,d)\n",
    "K = key(x) \n",
    "V = value(x) \n",
    "\n",
    "# matmul\n",
    "QK = Q @ K.transpose(-2, -1) # (1,N,d) @ (1,d,N) -> (1,N,N)\n",
    "A = QK  * C**-0.5 # attention matrix \n",
    "A.masked_fill_(mask[:T,:T] == 0, float(\"-inf\")) # applying mask\n",
    "A = F.softmax(input=A, dim=-1) # apply SoftMax: (1,N,N) normalizing to 0 and 1 in embedding dimension\n",
    "\n",
    "out = A @ V # (1,N,N) @ (1,N,d) -> (1,N,d)\n",
    "\n",
    "print(f'{out = }\\n') # new data representation\n",
    "print(f'{out.size() = }\\n') \n",
    "\n",
    "# x_before = x.detach().clone()\n",
    "x_after = x.detach().clone()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, comparing x before and after, we see that we get truely different representations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:          after:          diff:\n",
      " 3.205          -0.280           3.484\n",
      "-3.195          -1.152          -2.042\n",
      "-0.889          -1.069           0.180\n",
      " 1.705          -0.160           1.866\n",
      "-1.956          -1.956           0.000\n",
      "-0.859           1.007          -1.866\n",
      "-1.069          -0.889          -0.180\n",
      " 0.284          -1.759           2.042\n",
      "-0.701           2.783          -3.484\n"
     ]
    }
   ],
   "source": [
    "x_before_col1 = [elem for elem in x_before[0][:,0]]\n",
    "x_after_col1 = [elem for elem in x_after[0][:,0]]\n",
    "x_after_col1.reverse()\n",
    "\n",
    "print(f'before: {\"after:\":>15} {\"diff:\":>14}')\n",
    "for i in range(len(x_before_col1)):\n",
    "    print(f'{x_before_col1[i]: .3f} {x_after_col1[i]: >15.3f} {x_before_col1[i] - x_after_col1[i]: >15.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi', '!', '!', ' ', 'My', ' ', 'name', ' ', 'is', ' ', 'Donald', '.', ' ', 'What', ' ', 'is', ' ', 'your', ' ', 'name', '?', ' ', ':', ')']\n"
     ]
    }
   ],
   "source": [
    "spltting_pattern = re.compile(r'(?<=\\w)(?=[^\\w])|(?<=[^\\w])(?=\\w)|(?<=[^\\w])(?=\\s)|(?<=[^\\w])(?=[^w])')\n",
    "foo = 'Hi!! My name is Donald. What is your name? :)'\n",
    "res = spltting_pattern.split(foo)\n",
    "print(res)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
